# 데이터 분석

## 데이터 마이닝

### 데이터 마이닝 개요
- 모든 사용가능한 원천 데이터를 기반으로 감춰진 지식, 기대하지 못했던 경향 또는 새로운 규칙 등을 발견하고 유용한 정보로 활용
- 데이터 마이닝 5단계
    - 목적 정의 
    - 데이터 준비 : 데이터 정제, 데이터 양
    - 데이터 가공 : 목적 변수 정의, 필요한 데이터를 데이터 마이닝 SW에 적용할 수 있게 가공 및 준비
    - 데이터 마이닝 기법 적용
    - 검증

### 대표적 데이터 마이닝 기법
- 분류 : 기존의 분류, 정의된 집합에 배정
- 추정 : 연속된 변수의 값을 추정, 신경망 모형
- 연관 분석(Association Analysis) : 연관성 파악
- 예측 : 장바구니 분석, 의사결정나무, 신경망 모형
- 군집(Clustering) : 유사성에 의해 그룹화
- 기술(Description) : 데이터 가진 특징 및 의미를 단순하게 설명

### 분류 분석

- 데이터 분석 순서
    - 분석용 데이터 준비
    - 탐색적 분석 데이터 전처리
        - 속성간 상관관계 파악, 데이터 특성 파악, 분포 파악
        - 데이터 확인, 데이터 형식 변경, 결측 값 처리, 이상 값처리, 특성 조작, 데이터 차원 축소
    - 모델링
        - 회귀분석,분류분석,군집분석,연관분석
    - 모델 평가 및 검증
        - 결정계수, F통계량, t값, ROC Curve, 오분류표, 실루엣, DI
    - 모델 적응 운용 방안 수립

### Machine Learning Algorithms
- Classification : 지도학습
- Clusetering : 비지도학습(군집)
![graph](./img/머신러닝알고리즘.png)

### 분류분석의 종류
- 로지스틱 회귀
    - R프로그래밍에서 glm 사용
    - 독립변수 연속형, **종속 변수가 범주형**인 경우
    - 이항변수(0,1)로 되어 있을때, 종속변수와 독립변수 간의 관계식을 이용하여 분류하고자 할때 사용
    - 최대우도법, 가중최소자승법
    - sigmoid 함수를 이용해 연속형 0~1값으로 변경
    - probability(0~1사이) -> odds(0~무한대 변환한 값): 성공률 / 실패율 -> log odds(전체 실수 범위 -무한대~+무한대) -> sigmoid(0~1)사이의 값으로 바꾸는 함수
- 의사결정나무(Decision Tree)
    - 소집단으로 분류 또는 예측을 수행 분석 방법
    - 이전 분할에 영향을 받는다
    - 순수도가 증가하도록 분류나무를 형성
    - 독립변수(설명변수,예측변수,Feature)
    - 종속변수(목표변수,반응변수,LABEL)
    - 목표변수가 이산형인 경우 분류나무,연속형인 경우 회귀나무
    - 장점
        - 비모수적 모형으로 수학적 가정 불필요
        - 범주형과 수치형 변수를 모두 사용
    - 단점
        - 오차가 큼
        - 예측변수 효과 파악X
    - 의사결정나무의 결정규칙
        - 분리기준 
            - 지니지수 : 값이 작을수록 순수도가 높음
            - 엔트로피 지수 : 값이 작을수록 순수도가 높음
            - 카이제곱 통계량의 유의 확률 : 값이 작을수록 순수도가 높음
        - 정지규칙 : 불순도가 작을때
        - 가지치기 규칙 : Overfitting 가능성이 커짐, 이를 해결하기 위해 사용
        - 알고리즘
            - CHAID,CART(Classification And Regression Tree),ID2,C5.0,C4.5이 있으며, 하향식 접근법
- 앙상블
    - 여러개의 분류모형에 의한 결과를 종합하여 정확도를 높이는 방법
    - 성능을 분산시키기 때문에, 과적합 감소효과
    - 종류 
        - Voting : 서로 다른 여러개 알고리즘 분류기 사용
        - Bagging, Bootstrap AG : 서로 다른 훈련 데이터 샘플로 훈련, 서로 같은 알고리즘 분류기 결합, **중복허용**, 여러 모델이 병렬로 학습
        - Boosting : 순차적으로 학습, 이상치 약함, 분류가 잘못된 데이터에 대해서 가중치 부여
        - Random Forest : 배깅에 랜덤 과정을 추가한 방법, **설명변수의 일부분**만 고려, 여러 개의 의사결정 나무를 사용해 과적합 문제를 피함
- 신경망모형
- KNN, 베이즈분류 모형, SVM, 유전자 알고리즘

### KNN(K-Nearest Neighbors) : 이웃의 개수 만큼 가까운 멤버들과 비교하여 결과를 판단
![graph](./img/knn.png)
### SVM(Support Vector Machine) : 서로 다른 분류에 속한 데이터 간의 간격이 최대가 되는선
![graph](./img/svm.png)

### 인공 신경망(ANN) 모형
- 인공신경망을 이용하여 분류 및 군집
- 입력층,은닉층,출력층 
- 학습 : 올바른 출력이 나오도록 가중치를 조절
- 장점
    - 복잡한 비선형 관계 유용
    - 이상한 잡음에 대해서도 민감하게 반응 X
- 단점
    - 결과에 대한 해석 어려움

### 경사하강법(Gradient descent)
- 함수 기울기를 낮은 쪽으로 계속 이동
- 기울기의 최소값을 찾아냄
![graph](./img/경사하강법.png)

### 신경망 활성화 함수
- 신경망 활성화 함수
    - 계단함수 : 0 또는 1 결과
    - 부호함수 : -1 또는 1 결과
    - 선형함수 
    - Sigmoid : 연속형 0~1
    - softmax : 모든 로직의 합이 1, 각 범주에 속할 사후 **확률**을 제공
- 신경망 은닉 층, 은닉 노드
    - 은닉 층 적을경우 : Underfitting
    - 은닉 층 많은경우 : 기울기 소실 문제 및 과적합 문제 발생
    - 역전파 알고리즘 : 동일 입력층에 대해 원하는 값이 출력되도록 개개의 weight를 조정
    - 기울기 소실 : sigmoid 함수를 사용할 때 사용 => 해결 하기 위해 ReLu 등 다른 함수 사용

### 모형 평가
- 홀드아웃 
    - 원천 데이터를 랜덤하게 두 분류로 분리하여 교차검정을 실시하는 방법, 2종 오류 방지(불량이 아닌데,불량으로 판단)
    - idx <- sample(2,nrow(iris),replace =TRUE,prob=c(0.7,0.3)) // Train Data 70%, Test Data 30%
- 교차검증
    - 데이터가 적은 경우 사용하며, 클래스 불균형 데이터는 적합X(=결과가 한쪽으로 몰려있으면 안됨)
    - 반복적으로 성과를 측정하여 그 결과를 평균
    - 전체 데이터 Shuffle -> K개 데이터 분할 -> K-1개는 훈련용,K번측정 -> 결과
- 붓스트랩
    - 관측치를 한 번이상 훈련용 자료로 사용 **63.2%**
- 데이터 분할시 고려사항
![graph](./img/샘플링.png)

### **오류분표를 활용한 평가지표**
- Sensitivity : 실제값 TRUE 
- Precision : 예측 TRUE
- 암기!! : 실Sen,예Pre
![graph](./img/오류분표평가지표.png)
![graph](./img/오류분표평가지표2.png)
![graph](./img/오류분표평가지표3.png)

### 분류 모형 성능 평가
- ROC Curve : 밑부분의 면접이 넓을수록 좋음

### 군집 분석
- 유사 성격을 가지는 군집을 집단화 하고 군집들 사이의 관계를 분석하는 다변량분석 기법
- 거리 : 
    - 연속형 변수 : 유클리디안 거리, 표준화 거리, 마할라노비스, 체비셰프 거리, 맨하탄 거리, 캔버라 거리, 민코우스키 거리
    - 범주형 변수 : 자카드거리,코사인 거리

- 계측적 군집
    - 응집형 : 단일 연결법,Ward연결법(오차 제곱합),최단연결법(최소값),최장연결법(최대값),중심연결법(중심 간의 거리)
    - 분리형
- 분할적 군집
    - 프로토 타입 기반 : K 중신 군집
    - 분포기반
    - 밀도기반

### 계층적 군집
- 두 개체간의 거리에 기반하므로 거리 측정에 대한 정의가 필요
- 사전에 군집 수 K를 설정할 필요 없는 탐색적 모형
- 한 번 군집이 형성되면 군집에 속한 개체는 다른 군집으로 이동X
- 이상치에 민감,탐색적 모형

### 비계층적 군집
- 분할적 군집 방법 
    - k-means : 사전에 군집의 수 k를 정해야함.
        - k-means 절차 : k개 임의로 선택 -> 가까운 군집의 중심에 할당 -> 자료들의 평균을 계산하여 군집의 중심을 갱신
    - DBSCAN : 밀도 기반, 반경 내에 점이 n개 이상 있으면 하나의 군집으로 인식, 임의적 모양의 군집 분석에 용이
    - 혼합분포 군집 : EM 알고리즘 사용

### 군집화 평가지수
- 실루엣 계수
    - 실루엣 지표가 1에 가까울수록 군집화가 잘 되었다고 판단
- Dunn Index

### SOM(Self-Organizing Maps)
- 개요
    - 인공신경망의 한 종류, 차원축소와 군집화를 동시에 수행
    - 비지도학습의 한 가지 방법
    - 고차원 -> 저차원 변환해서 보는데 편함
- SOM 과정(경쟁 학습)
    - 단계1: SOM의 연결강도 초기화
    - 단계2 : 입력 벡터와 경쟁층 노드간의 계산 및 입력벡터와 가까운 노드 선택 => 경쟁
    - 단계3 : 선택된 노드와 이웃 노드의 가중치 갱신 => 협력 및 적응
- SOM vs 신경망 모형
    - 신경망 모형은 Layer, SOM 은 2차원 그리드 구성
    - 신경망 모형은 에러 수정 학습, SOM 은 경쟁학습
    - 신경망 모형은 역전파 알고리즘 SOM 은 전방패스 사용해 속도가 빠름

### 연관분석
- 알고리즘
    - Apriori 알고리즘 : 발생 빈도를 기반으로 연관관계
    - FP Growth : Apriori 단점을 보완하기 위해 FT-tree와 node,link 특별한 자료 구조 사용
- 장점 : 비목적성 분석, 분석 계산이 간편
- 단점 : 너무 세분화되면 관계 Find 어려움

### 연관규칙 측정지표
- 지지도 : 전체 거래항목 중 A와 B동시에 포함하여 거래하는 비율 P(A∩B)
- 신뢰도 : 상품 A를 포함하는 거래 중 A와 B동시에 거래되는 비율 P(B|A) = P(A∩B) / P(A)
- 향상도 : P(A∩B) / P(A) * P(B)
- 향상도 해석 방법
    - 1 < 향상도 : 연관성이 높음
    - 1 = 향상도 : 독립
    - 1 > 향상도 : 서로 음의 상관관계